[
  {
    "name": "Tacred",
    "description": "Tacred is a relation extraction dataset with around 15,000 sentences",
    "available_transformation_type": [
      "domain",
      "ut",
      "domain_domain",
      "domain_ut",
      "ut_ut"
    ],
    "dataset_size": 15509,
    "models": [
      {
        "model_name": "LSTM-ATT",
        "paper_link": "https://www.aclweb.org/anthology/D17-1004.pdf",
        "github_link": "https://github.com/yuhaozhang/tacred-relation",
        "paper_name": "Position-aware Attention and Supervised Data Improve Slot Filling",
        "metric": {
          "F1": 65.4
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-EMNLP-zhang2017position/images/sha256-0a5891a6af5e7fee13fd067be9fd5fd13dddabbfbba329e10e210173e21d74d6?context=explore"
      },
      {
        "model_name": "GCN",
        "paper_link": "https://www.aclweb.org/anthology/D18-1244.pdf",
        "github_link": "https://github.com/qipeng/gcn-over-pruned-trees",
        "paper_name": "Graph Convolution over Pruned Dependency Trees Improves Relation Extraction",
        "metric": {
          "F1": 62.03
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-EMNLP-zhang2018graph/images/sha256-e71ba8c49bf29ebed9b96c74ae5cba45af6549e8fe0f8709bf70a3ca4dd00b38?context=explore"
      },
      {
        "model_name": "AGGCN",
        "paper_link": "https://www.aclweb.org/anthology/P19-1024.pdf",
        "github_link": "https://github.com/Cartus/AGGCN",
        "paper_name": "Attention Guided Graph Convolutional Networks for Relation Extraction",
        "metric": {
          "F1": 67.41
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-ACL-guo2019aggcn/images/sha256-cd03dca8ec8f450a66fc2cba58224a1611c21c24c9e6822348e106ba64960ed6?context=explore"
      },
      {
        "model_name": "BERT-base-uncased",
        "paper_link": "https://arxiv.org/abs/1810.04805",
        "github_link": "https://github.com/huggingface/transformers",
        "paper_name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "metric": {
          "F1": 68.01
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-NAACL-devlin2019bert/images/sha256-c4d45371fbe70e42447556cd33c667f710bde3f12a52676110ec5b138d19ccf6?context=explore"
      },
      {
        "model_name": "BERT-large-uncased",
        "paper_link": "https://arxiv.org/abs/1810.04805",
        "github_link": "https://github.com/huggingface/transformers",
        "paper_name": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "metric": {
          "F1": 67.73
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-NAACL-devlin2019bert/images/sha256-c4d45371fbe70e42447556cd33c667f710bde3f12a52676110ec5b138d19ccf6?context=explore"
      },
      {
        "model_name": "CP-finetune",
        "paper_link": "https://aclanthology.org/2020.emnlp-main.298.pdf",
        "github_link": "https://github.com/thunlp/RE-Context-or-Names",
        "paper_name": "Learning from Context or Names? An Empirical Study on Neural Relation Extraction",
        "metric": {
          "F1": 68.60
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-EMNLP-peng2020learning/images/sha256-756006148ce66c1f3959384284374a4d047a2e64b035ee8c72d184fcb7ea116a?context=explore"
      },
      {
        "model_name": "KD4NRE",
        "paper_link": "https://ojs.aaai.org/index.php/AAAI/article/view/6509",
        "github_link": "https://github.com/zzysay/KD4NRE",
        "paper_name": "Distilling Knowledge from Well-informed Soft Labels for Neural Relation Extraction",
        "metric": {
          "F1": 68.16
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-AAAI-zhang2020distilling/images/sha256-b92248b57cc1c4127f5996bf0655c71db576367993a4870db4514bcd405b098a?context=explore"
      },
      {
        "model_name": "LUKE",
        "paper_link": "https://aclanthology.org/2020.emnlp-main.523.pdf",
        "github_link": "https://github.com/studio-ousia/luke",
        "paper_name": "LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention",
        "metric": {
          "F1": 72.66
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-EMNLP-yamada2020luke/images/sha256-fbbe391256f450b7e65645d9af42ec780ff5ff5485eeef2a8ed6826226596c85?context=explore"
      },
      {
        "model_name": "SPANBERT",
        "paper_link": "https://arxiv.org/abs/1907.10529",
        "github_link": "https://github.com/facebookresearch/SpanBERT",
        "paper_name": "SpanBERT: Improving Pre-training by Representing and Predicting Spans",
        "metric": {
          "F1": 70.81
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/COREF-TACL-joshi2020spanbert/images/sha256-3567ebdfc08c0b792d0ea11b2c2b861a005ca572dea760b20fb1507b7b58dde0?context=explore"
      },
      {
        "model_name": "TRE",
        "paper_link": "https://arxiv.org/abs/1906.03088",
        "github_link": "https://github.com/DFKI-NLP/TRE",
        "paper_name": "Improving Relation Extraction by Pre-trained Language Representations",
        "metric": {
          "F1": 67.42
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-AKBC-alt2019improving/images/sha256-ccc9b0425a3e076f8250924467993b99a8754c09db7058985d67d02e2ddb02a0?context=explore"
      },
      {
        "model_name": "ERICA",
        "paper_link": "https://arxiv.org/pdf/2012.15022.pdf",
        "github_link": "https://github.com/thunlp/ERICA",
        "paper_name": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning",
        "metric": {
          "F1": 67.52
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-ACL-qin2020erica/images/sha256-f9a25dfc0077863a3dd65b1919c7e67c8626926c30e76bff65431cd13623c911?context=explore"
      },
      {
        "model_name": "NLL",
        "paper_link": "https://arxiv.org/pdf/2104.08656.pdf",
        "github_link": "https://github.com/wzhouad/NLL-IE",
        "paper_name": "Learning from Noisy Labels for Entity-Centric Information Extraction",
        "metric": {
          "F1": 70.94
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-EMNLP-zhou2021learning/images/sha256-26e1e21500ac5c985566d34934a514541e53112c7bc1e175c5360f4b4496756c?context=explore"
      },
      {
        "model_name": "Roberta-base",
        "paper_link": "https://arxiv.org/pdf/1907.11692.pdf",
        "github_link": "https://github.com/pytorch/fairseq",
        "paper_name": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
        "metric": {
          "F1": 69.07
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-roberta_base-entity_marker/images/sha256-ab43d7f91c1ff37476160f0799c3a7ad14fea6e90fbe392c22fd3377654b32b2?context=explore"
      },
      {
        "model_name": "MTB",
        "paper_link": "https://arxiv.org/pdf/1906.03158.pdf",
        "github_link": "https://github.com/thunlp/RE-Context-or-Names/tree/master/pretrain",
        "paper_name": "Matching the Blanks: Distributional Similarity for Relation Learning",
        "metric": {
          "F1": 67.51
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-ACL-soares2019matching/images/sha256-e2c4f187710dc3fbdd56ecfb9a38d525aeaf2906a45a945ee086977ff73ae295?context=explore"
      }
    ]
  },
  {
    "name": "NYT",
    "description": "NYT is a distantly supervised relation extraction dataset with around 172,000 sentences",
    "dataset_size": 172448,
    "available_transformation_type": [
      "domain",
      "ut",
      "domain_domain",
      "domain_ut",
      "ut_ut"
    ],
    "models": [
      {
        "model_name": "PCNN-ATT",
        "paper_link": "https://www.aclweb.org/anthology/P16-1200.pdf",
        "github_link": "https://github.com/thunlp/OpenNRE",
        "paper_name": "Neural Relation Extraction with Selective Attention over Instances",
        "metric": {
          "AUC": 0.3366,
          "F1": 0.412
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-ACL-lin2016neural/images/sha256-a063a66d34c05ac49fee1d9eccccb91c44c8214b9d63375d19d4b49ed296731f?context=explore"
      },
      {
        "model_name": "PCNN+ATT RA+BAG ATT",
        "paper_link": "https://arxiv.org/abs/1904.00143",
        "github_link": "https://github.com/ZhixiuYe/Intra-Bag-and-Inter-Bag-Attentions",
        "paper_name": "Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions",
        "metric": {
          "AUC": 0.4212,
          "F1": 0.4555
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-NAACL-ye-ling-2019-distant/images/sha256-19f4fd7935896ba5dbf5270c69fe02bdc8effb9361e1003a5e672b9011be8ec5?context=explore"
      },
      {
        "model_name": "PCNN",
        "paper_link": "https://www.aclweb.org/anthology/D15-1203.pdf",
        "github_link": "https://github.com/thunlp/OpenNRE",
        "paper_name": "Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks",
        "metric": {
          "AUC": 0.3463,
          "F1": 0.4087
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-EMNLP-zeng2015distant/images/sha256-bdcc438bec27362790cad5991640021943b0b3ef9f3743d2c2ecf3a36ebc45eb?context=explore"
      },
      {
        "model_name": "SeG",
        "paper_link": "https://arxiv.org/pdf/1911.11899.pdf",
        "github_link": "https://github.com/tmliang/SeG",
        "paper_name": "Self-Attention Enhanced Selective Gate with Entity-Aware Embedding for Distantly Supervised Relation Extraction",
        "metric": {
          "AUC": 0.4575,
          "F1": 0.4927
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-AAAI-li2020self/images/sha256-a6ad3acd7a87598be9df03f0f7606c75f5544aa545182b8380b650d3514a4623?context=explore"
      },
      {
        "model_name": "dsre-vae",
        "paper_link": "https://aclanthology.org/2021.naacl-main.2.pdf",
        "github_link": "https://github.com/fenchri/dsre-vae",
        "paper_name": "Distantly Supervised Relation Extraction with Sentence Reconstruction and Knowledge Base Priors",
        "metric": {
          "AUC": 0.4024,
          "F1": 0.4449
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-arxiv-liang2021distantly/images/sha256-a15219fd4c72d29cbf6459952a27f4651a341114e7a285780e12f85d658a5f16?context=explore"
      },
      {
        "model_name": "DISTRE",
        "paper_link": "https://www.aclweb.org/anthology/P19-1134",
        "github_link": "https://github.com/DFKI-NLP/DISTRE",
        "paper_name": "Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction",
        "metric": {
          "AUC": 0.4225,
          "F1": 0.4864
        },
        "dockerhub_link": "https://hub.docker.com/layers/fudannlp/reimplement/RE-ACL-alt-etal-2019-fine/images/sha256-f55d99f4c52eddcae763eb2e67cb12b5c53cbf590d6ade032c5aebbb9473689c?context=explore"
      }
    ]
  }
]